) %>%
na.omit() %>%
group_by(numb, what) %>%
summarize(X1 = paste(X1, collapse = " ")) %>%
pivot_wider(names_from = what, values_from = X1)  %>%
separate(time_sub, c("start_t", "end_t"), sep = " --> ")  %>%
mutate(season = as.numeric(info_ser[[1]]),
episode = as.numeric(info_ser[[2]]))  %>%
mutate_at(c("start_t", "end_t"), as.POSIXct, format = "%H:%M:%OS") %>%
ungroup()
# shorturl.at/cpRU2
message(paste0("File ", link_file, " imported!"))
return(subt2)
}
subt_folder <- "/Users/heverz/Documents/R_projects/RDen/static/data/data_post7/breaking bad"
list_files <- list.files(subt_folder, full.names = TRUE)
# bb stands for breaking bad
bb <- map_dfr(list_files, import_sub)
bb <- bb %>%
mutate(dial = str_remove_all(dial, pattern = "(\\[.*?\\])|(<.*>)|(Sync and.*)"))
# tokenize
stop_words <- get_stopwords(language = "en")
bb_words <- bb %>%
unnest_tokens(input = dial, output = "words", token = "words", format = "text")  %>%
filter(str_detect(words, "[[:alpha:]]"),
!words %in% stop_words$word)
tab <- bb_words %>%
group_by(words) %>%
summarize(frequency = n()) %>%
arrange(desc(frequency)) %>%
mutate(position = seq_along(words)) %>%
filter(position %in% 1:7 | words %in% c("bitch", "bitches"))
do.call("rbind", list(tab[1:7,], rep("...", 3), tab[8:9,]))
bb_words %>%
filter(str_detect(words, "^bitch*") | words %in% c("shit", "fuck", "damn", "asshole", "assholes", "slut", "whore", "goddamn", "cunt", "crap", "prick")) %>%
group_by(words) %>%
summarize(frequency = n()) %>%
arrange(desc(frequency)) %>%
head(5)
bb_words %>%
filter(str_detect(words, "^bitch*")) %>%
mutate(season = paste("Season ", season)) %>%
group_by(season) %>%
summarize(n = n()) %>%
ggplot(aes(x = season, y = n, group = season, fill = as.factor(season))) +
geom_col(colour = "black", size = 0.3) +
scale_fill_brewer(palette="Dark2") +
scale_y_continuous(breaks = seq(0,30, 5), limits = c(0, 30)) +
labs(x = NULL,
y = "number of times used",
title =  expression("Words" ~italic("BITCH + BITCHES"))) +
geom_text(aes(y = n - 2,
label = n),
size = 4) +
theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
axis.text.x  = element_text(hjust = 0.5, size = 10, face = "bold"),
legend.position = "none")
bb_words %>%
filter(str_detect(words, "^bitch*")) %>%
mutate(season = paste("Season ", season)) %>%
group_by(season) %>%
summarize(n = n()) %>%
arrange(season) %>%
mutate(episode_n = c(7, 13, 13, 13, 16), mean_episode = n/episode_n)
# %>%
#   ggplot(aes(x = season, y = mean_episode, group = season, fill = as.factor(season))) +
#     geom_col(colour = "black", size = 0.3) +
#     scale_fill_brewer(palette="Dark2") +
#     scale_y_continuous(breaks = seq(0,2.5, 0.5), limits = c(0, 2.5)) +
#     labs(x = NULL,
#          y = NULL,
#          # y = expression("number of times used"~bold("per episode")),
#          title = expression(~italic("BITCH + BITCHES"): "average per episode")) +
#     geom_text(aes(y = mean_episode - 0.2,
#                  label = round(mean_episode, 2)),
#                   size = 4) +
#     theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
#           axis.text.x  = element_text(hjust = 0.5, size = 10, face = "bold"),
#           legend.position = "none")
bb_words %>%
filter(str_detect(words, "^bitch*")) %>%
mutate(season = paste("Season ", season)) %>%
group_by(season, episode) %>%
summarize(n = n()) %>%
# ggplot(aes( n)) +
#   geom_histogram(binwidth = 1)
ggplot(aes(x = episode, y = n,  fill = as.factor(season))) +
geom_col(position = "dodge2", colour = "black", size = 0.3) +
scale_fill_brewer(palette="Dark2") +
facet_grid(season ~ .) +
labs(x = "episode",
y = "number of time used",
title = expression("Words:"~italic("BITCH + BITCHES"))) +
scale_x_continuous(breaks = seq(1,16, 1), limits = c(0.5, 16.5)) +
geom_text(aes(y = 0.6,
label = n),
size = 3) +
theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
axis.title.x = element_text(hjust = 0.5, size = 10, face = "bold"),
legend.position = "none")
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::letterCloud(word = "B")
bb_wordcloud
# webshot::install_phantomjs()
#
# saveWidget(bb_wordcloud,"bb_wordcloud.html", selfcontained = TRUE)
frameWidget(bb_wordcloud)
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2(word = "B")
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2()
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2()
bb_wordcloud
# webshot::install_phantomjs()
#
# saveWidget(bb_wordcloud,"bb_wordcloud.html", selfcontained = TRUE)
frameWidget(bb_wordcloud)
bb_wordcloud
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2()
bb_wordcloud <-
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2()
bb_wordcloud
bb_wordcloud
blogdown:::serve_site()
# webshot::install_phantomjs()
#
saveWidget(bb_wordcloud,"bb_wordcloud.html", selfcontained = TRUE)
library(wordcloud)
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud::wordcloud()
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud(bb_wordcloud)
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n())
View(bb_wordcloud)
wordcloud(bb_wordcloud$words, bb_wordcloud$freq)
library(tidytext)
library(tidyverse)
library(data.table)
library(lubridate)
library(vroom)
library(svDialogs)
library(stringr)
library(wordcloud)
library(webshot)
library(htmlwidgets)
library(widgetframe)
import_sub <- function(link_file){
#extract season and episode from file name
info_ser <- str_split(str_extract(link_file, "[:digit:]+x[:digit:]+"), "x", simplify = TRUE)
subt <- vroom_lines(link_file)
# last 3 rows are specifications for fonts and colors
subt <- subt[1:(length(subt)-3)]
# extract number (order) of  subtitles and positions
arg <- list(subt, "^[:digit:]+$")
numb_pos <- map(list(str_subset, str_which), exec, !!!arg)
# this create a col where numbers are repeated
subt <- bind_cols(numb = as.numeric(rep(numb_pos[[1]],
diff(
c(numb_pos[[2]], length(subt)+1)
))),
X1 = subt)
subt2 <- subt %>%
mutate(what =
case_when(
str_detect(X1, "[:digit:]+:[:digit:]+") ~ "time_sub",
str_detect(X1, "[:alpha:]") ~ "dial")
) %>%
na.omit() %>%
group_by(numb, what) %>%
summarize(X1 = paste(X1, collapse = " ")) %>%
pivot_wider(names_from = what, values_from = X1)  %>%
separate(time_sub, c("start_t", "end_t"), sep = " --> ")  %>%
mutate(season = as.numeric(info_ser[[1]]),
episode = as.numeric(info_ser[[2]]))  %>%
mutate_at(c("start_t", "end_t"), as.POSIXct, format = "%H:%M:%OS") %>%
ungroup()
# shorturl.at/cpRU2
message(paste0("File ", link_file, " imported!"))
return(subt2)
}
subt_folder <- "/Users/heverz/Documents/R_projects/RDen/static/data/data_post7/breaking bad"
list_files <- list.files(subt_folder, full.names = TRUE)
# bb stands for breaking bad
bb <- map_dfr(list_files, import_sub)
bb <- bb %>%
mutate(dial = str_remove_all(dial, pattern = "(\\[.*?\\])|(<.*>)|(Sync and.*)"))
# tokenize
stop_words <- get_stopwords(language = "en")
bb_words <- bb %>%
unnest_tokens(input = dial, output = "words", token = "words", format = "text")  %>%
filter(str_detect(words, "[[:alpha:]]"),
!words %in% stop_words$word)
tab <- bb_words %>%
group_by(words) %>%
summarize(frequency = n()) %>%
arrange(desc(frequency)) %>%
mutate(position = seq_along(words)) %>%
filter(position %in% 1:7 | words %in% c("bitch", "bitches"))
do.call("rbind", list(tab[1:7,], rep("...", 3), tab[8:9,]))
bb_words %>%
filter(str_detect(words, "^bitch*") | words %in% c("shit", "fuck", "damn", "asshole", "assholes", "slut", "whore", "goddamn", "cunt", "crap", "prick")) %>%
group_by(words) %>%
summarize(frequency = n()) %>%
arrange(desc(frequency)) %>%
head(5)
bb_words %>%
filter(str_detect(words, "^bitch*")) %>%
mutate(season = paste("Season ", season)) %>%
group_by(season) %>%
summarize(n = n()) %>%
ggplot(aes(x = season, y = n, group = season, fill = as.factor(season))) +
geom_col(colour = "black", size = 0.3) +
scale_fill_brewer(palette="Dark2") +
scale_y_continuous(breaks = seq(0,30, 5), limits = c(0, 30)) +
labs(x = NULL,
y = "number of times used",
title =  expression("Words" ~italic("BITCH + BITCHES"))) +
geom_text(aes(y = n - 2,
label = n),
size = 4) +
theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
axis.text.x  = element_text(hjust = 0.5, size = 10, face = "bold"),
legend.position = "none")
bb_words %>%
filter(str_detect(words, "^bitch*")) %>%
mutate(season = paste("Season ", season)) %>%
group_by(season) %>%
summarize(n = n()) %>%
arrange(season) %>%
mutate(episode_n = c(7, 13, 13, 13, 16), mean_episode = n/episode_n)
# %>%
#   ggplot(aes(x = season, y = mean_episode, group = season, fill = as.factor(season))) +
#     geom_col(colour = "black", size = 0.3) +
#     scale_fill_brewer(palette="Dark2") +
#     scale_y_continuous(breaks = seq(0,2.5, 0.5), limits = c(0, 2.5)) +
#     labs(x = NULL,
#          y = NULL,
#          # y = expression("number of times used"~bold("per episode")),
#          title = expression(~italic("BITCH + BITCHES"): "average per episode")) +
#     geom_text(aes(y = mean_episode - 0.2,
#                  label = round(mean_episode, 2)),
#                   size = 4) +
#     theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
#           axis.text.x  = element_text(hjust = 0.5, size = 10, face = "bold"),
#           legend.position = "none")
bb_words %>%
filter(str_detect(words, "^bitch*")) %>%
mutate(season = paste("Season ", season)) %>%
group_by(season, episode) %>%
summarize(n = n()) %>%
# ggplot(aes( n)) +
#   geom_histogram(binwidth = 1)
ggplot(aes(x = episode, y = n,  fill = as.factor(season))) +
geom_col(position = "dodge2", colour = "black", size = 0.3) +
scale_fill_brewer(palette="Dark2") +
facet_grid(season ~ .) +
labs(x = "episode",
y = "number of time used",
title = expression("Words:"~italic("BITCH + BITCHES"))) +
scale_x_continuous(breaks = seq(1,16, 1), limits = c(0.5, 16.5)) +
geom_text(aes(y = 0.6,
label = n),
size = 3) +
theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
axis.title.x = element_text(hjust = 0.5, size = 10, face = "bold"),
legend.position = "none")
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n())  %>%
head(300)
wordcloud(bb_wordcloud$words, bb_wordcloud$freq, colors = TRUE)
wordcloud(bb_wordcloud$words, bb_wordcloud$freq, colors = TRUE, random.color = TRUE)
wordcloud(bb_wordcloud$words, bb_wordcloud$freq, random.color = TRUE)
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2()
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::letterCloud("Bitch")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::letterCloud("B")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::letterCloud("B")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::letterCloud("Bitch")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::letterCloud("Bitch")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::letterCloud("Bitch")
bb_wordcloud
b_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::letterCloud("Bitch")
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2()
bb_wordcloud
b_wordcloud
b_wordcloud
bb_wordcloud
bb_wordcloud
bb_wordcloud
blogdown:::serve_site()
install.packages("kableExtra")
```{r list_tab, echo=FALSE, eval=TRUE}
install.packages(c("cowplot", "fmsb", "ggthemes"))
library(tidytext)
library(tidyverse)
library(data.table)
library(lubridate)
library(vroom)
library(svDialogs)
library(stringr)
library(wordcloud)
library(webshot)
library(htmlwidgets)
library(widgetframe)
# function to import subtitles that are locate all in a folder
import_sub <- function(link_file){
#extract season and episode from file name
info_ser <- str_split(str_extract(link_file, "[:digit:]+x[:digit:]+"), "x", simplify = TRUE)
subt <- vroom_lines(link_file)
# last 3 rows are specifications for fonts and colors
subt <- subt[1:(length(subt)-3)]
# extract number (order) of  subtitles and positions
arg <- list(subt, "^[:digit:]+$")
numb_pos <- map(list(str_subset, str_which), exec, !!!arg)
# this create a col where numbers are repeated
subt <- bind_cols(numb = as.numeric(rep(numb_pos[[1]],
diff(
c(numb_pos[[2]], length(subt)+1)
))),
X1 = subt)
subt2 <- subt %>%
mutate(what =
case_when(
str_detect(X1, "[:digit:]+:[:digit:]+") ~ "time_sub",
str_detect(X1, "[:alpha:]") ~ "dial")
) %>%
na.omit() %>%
group_by(numb, what) %>%
summarize(X1 = paste(X1, collapse = " ")) %>%
pivot_wider(names_from = what, values_from = X1)  %>%
separate(time_sub, c("start_t", "end_t"), sep = " --> ")  %>%
mutate(season = as.numeric(info_ser[[1]]),
episode = as.numeric(info_ser[[2]]))  %>%
mutate_at(c("start_t", "end_t"), as.POSIXct, format = "%H:%M:%OS") %>%
ungroup()
# shorturl.at/cpRU2
message(paste0("File ", link_file, " imported!"))
return(subt2)
}
# folder and files
subt_folder <- "/Users/heverz/Documents/R_projects/RDen/static/data/data_post7/breaking bad"
list_files <- list.files(subt_folder, full.names = TRUE)
# import - bb stands for breaking bad
bb <- map_dfr(list_files, import_sub)
bb <- bb %>%
mutate(dial = str_remove_all(dial, pattern = "(\\[.*?\\])|(<.*>)|(Sync and.*)"))
# tokenize
stop_words <- get_stopwords(language = "en")
bb_words <- bb %>%
unnest_tokens(input = dial, output = "words", token = "words", format = "text")  %>%
filter(str_detect(words, "[[:alpha:]]"),
!words %in% stop_words$word)
# table1
tab <- bb_words %>%
group_by(words) %>%
summarize(frequency = n()) %>%
arrange(desc(frequency)) %>%
mutate(position = seq_along(words)) %>%
filter(position %in% 1:7 | words %in% c("bitch", "bitches"))
tab1 <-
do.call("rbind", list(tab[1:7,], rep("...", 3), tab[8:9,])) %>%
tibble()
tab1
View(tab1)
tab1
View(tab1)
tab1 <-
do.call("rbind", list(tab[1:7,], rep("...", 3), tab[8:9,])) %>%
as.data.frame()
tab1
knitr::kable(tab1)
blogdown:::serve_site()
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2(shape = "circle")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2(shape = "pentagon")
bb_wordcloud
bb_wordcloud
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2(shape = "pentagon")
View(bb_wordcloud)
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2(shape = "pentagon")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
wordcloud2::wordcloud2(shape = "triangle")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
head(1000) %>%
wordcloud2::wordcloud2(shape = "triangle")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
head(3000) %>%
wordcloud2::wordcloud2(shape = "triangle")
bb_wordcloud
bb_wordcloud <-
bb_words %>%
group_by(words) %>%
summarize(freq = n()) %>%
head(2000) %>%
wordcloud2::wordcloud2(shape = "triangle")
bb_wordcloud
blogdown:::serve_site()
blogdown::build_site()
build_site()
blogdown::build_site()
blogdown::build_site()
blogdown:::serve_site()
library(svDialogs)
dlg_list(1:5)
dlgList(1:5, multiple = TRUE, title = "Select the subject")$res
dlgList(1:5, multiple = TRUE, title = "Select the subject", gui = .GUI)$res
blogdown::build_site()
git add .
blogdown::build_site()
blogdown::build_site()
